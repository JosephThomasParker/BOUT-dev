%% Developers manual for C++ BOUT code

\documentclass[12pt]{article}
\usepackage[nofoot]{geometry}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.95,0.95,0.95}
\lstset{
	backgroundcolor=\color{lbcolor},
        language=C++,
	keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
	identifierstyle=\ttfamily,
	commentstyle=\color[rgb]{0.133,0.545,0.133},
	stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
	showstringspaces=false,
	basicstyle=\small,
	numberstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	numbersep=10pt,
	tabsize=2,
	breaklines=true,
	prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
	breakatwhitespace=false,
	aboveskip={0.5\baselineskip},
        columns=fixed,
        upquote=true,
        extendedchars=true,
        morekeywords={string,Field2D,Field3D,Vector2D,Vector3D,BoutReal,FieldGroup,dcomplex},
}

% Add an index
\usepackage{makeidx}
\makeindex

%% Modify margins
\addtolength{\oddsidemargin}{-.25in}
\addtolength{\evensidemargin}{-.25in}
\addtolength{\textwidth}{0.5in}
\addtolength{\textheight}{0.25in}
%% SET HEADERS AND FOOTERS

\pagestyle{fancy}
\fancyfoot{}
\renewcommand{\sectionmark}[1]{         % Lower case Section marker style
  \markright{\thesection.\ #1}}
\fancyhead[LE,RO]{\bfseries\thepage}    % Page number (boldface) in left on even
                                        % pages and right on odd pages 
\renewcommand{\headrulewidth}{0.3pt}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bf #1}}

%% commands for boxes with important notes
\newlength{\notewidth}
\addtolength{\notewidth}{\textwidth}
\addtolength{\notewidth}{-3.\parindent}
\newcommand{\note}[1]{
\fbox{
\begin{minipage}{\notewidth}
{\bf NOTE}: #1
\end{minipage}
}}

\newcommand{\pow}{\ensuremath{\wedge} }
\newcommand{\poweq}{\ensuremath{\wedge =} }

\newcommand{\deriv}[2]{\ensuremath{\frac{\partial #1}{\partial #2}}}

\newcommand{\rbtsq}{\ensuremath{\left(RB_\theta\right)^2}}
\newcommand{\sbt}{\ensuremath{\sigma_{B\theta}}}
\newcommand{\apar}{\ensuremath{A_{||}}}
\newcommand{\Bthe}{\ensuremath{B_\theta}}
\newcommand{\Bzeta}{\ensuremath{B_\zeta}}
\newcommand{\hthe}{\ensuremath{h_\theta}}

\begin{document}

\title{BOUT++ Developers' Manual}
\author{B.Dudson, University of York}

\maketitle

\tableofcontents

\section{Introduction}

This is a manual describing the core BOUT++ code\cite{Dudson2009,dudson-2008-arxiv},
and is intended for anyone who
wants to work on improving BOUT++. It does its best to describe
the details of how BOUT++ works, and assumes that the user is very comfortable
with C++. For a general introduction, and instructions for using BOUT++
see the users' guide. The user's guide assumes only minimal knowledge of C++,
and provides only those details needed to use BOUT++. 

Since BOUT++ is a scientific code, it is constantly changing and (hopefully)
being improved. This provides a moving target for documentation, and means
that describing all the details of how BOUT++ works in one document is probably
impossible. This is particularly true since often our first priority is to
write papers and code - not documentation - and so whatever is documented
is likely to be slightly out of date. A source of up-to-date documentation
of the BOUT++ code is the comments and Doxygen tags: running \code{doxygen}
on the source should produce a set of HTML documentation. See
\file{www.doxygen.org} for more details.

\subsection{Using the BOUT++ repository}

As of June 2009, the BOUT++ distribution is hosted on Github: \index{Github}

\file{http://github.com/bendudson/BOUT/}

For a full guide to using Git, see the git website\footnote{\texttt{http://git-scm.com/}} or
online tutorials. This manual just explains some basic ways to use Git, and the recommended work flow
when working with BOUT++.

If you're just starting with BOUT++, current developers will want to check
your changes before submitting them to the repository. In this case
you should clone (checkout) the git repository, make any changes and
then submit patches to one of the developers (e.g.
to \texttt{bd512@york.ac.uk}). Fortunately Git makes this process quite easy:
First get a copy of BOUT++
\begin{verbatim}
$ git clone git://github.com/bendudson/BOUT.git
\end{verbatim}
The BOUT++ repository will now be in a directory called ``BOUT''
(sorry - github doesn't like '+' in project names). To get the latest
changes (\code{svn update} equivalent), use
\begin{verbatim}
$ git pull
\end{verbatim}
To see the status of the repository, commits etc. use 
\begin{verbatim}
$ gitk
\end{verbatim}
This is also useful for showing what changes you've made which need to be
committed, or which haven't yet been sent to the main repository.

You can make edits as normal, and commit them using
\begin{verbatim}
$ git commit -a
\end{verbatim}
which is pretty much the equivalent of \code{svn commit} in that
it commits all changes, though importantly it doesn't send them to
a central server. To see which changes will be committed, use
\begin{verbatim}
$ git status
\end{verbatim}
To choose which files you want to commit, use 
\begin{verbatim}
$ git add file1, file2, ...
$ git commit
\end{verbatim}
(Git can actually only commit selected parts of files if you want). To 
make using Git easier, you can create a config file \file{\$HOME/.gitconfig}
containing:
\begin{lstlisting}[language=bash,numbers=none]
[user]
	name = Ben Dudson
	email = bd512@york.ac.uk

[alias]
	st = status
	ci = commit
	br = branch
	co = checkout
	df = diff
	lg = log -p
	who = shortlog -s --
\end{lstlisting}
(though obviously you should change the name and email).

Once you're done making changes, you should first pull the latest changes
from the server:
\begin{verbatim}
$ git pull
\end{verbatim}
{\bf Read carefully} what git prints out. If there are conflicts
then git will try to resolve them, but in some cases you will have 
to resolve them yourself. To see a list of conflicting changes
run \code{git status} (or \code{git st} if you're using the above
\file{.gitconfig} file). Once you've finished resolving conflicts,
run \code{git commit -a} to commit the merge.

After you've got the latest changes, and resolved conflicts, create
a patch:
\begin{verbatim}
$ git format-patch origin/master --stdout > your-patch-file.diff
\end{verbatim}
Now you can email this patch to someone who can commit to the Git archive
(e.g. Ben Dudson, bd512@york.ac.uk).

\subsubsection{Developing BOUT++}

If you are doing a lot of development of BOUT++, it will probably make sense
for you to push changes directly to the online repository. 
In this case you'll need to sign up for an account on \file{github.com},
then upload an ssh key and ask to be added. The process is
then almost identical except that you clone using SSH:
\begin{verbatim}
$ git clone git@github.com:bendudson/BOUT.git
\end{verbatim}
and rather than creating a patch, you push changes to the repository:
\begin{verbatim}
$ git push
\end{verbatim}

\subsubsection{Accessing github from behind a firewall}

If you're working on a machine which can't access github directly
(such as grendel, smaug etc. at LLNL), you can still seamlessly access
github by using another machine as a proxy over SSH. To do this,
edit your SSH config file \texttt{~/.ssh/config} and add the following lines:
\begin{verbatim}
Host        gh
HostName    github.com
User        git
ProxyCommand    ssh -q -x user@euclid.nersc.gov nc %h %p
\end{verbatim}
where \texttt{euclid.nersc.gov} can be replaced by any machine you can access
which has netcat (\texttt{nc}) installed, and which can access github.com. 
If you have set up a github account with SSH keys, you should now be able to
get a copy of BOUT++ by running
\begin{verbatim}
$ git clone gh:bendudson/BOUT
\end{verbatim}

\subsubsection{Creating a private repository}

Whilst we would prefer it if improvements to BOUT++ were shared, 
sometimes you might want to keep changes private for a while before
publishing them. Creating a private repository with Git is very simple,
because every clone of a repository is itself a repository.
Git doesn't have the concept of a
central repository, which can seem strange coming from the world of SVN and
CVS. What it means is that you can create your own private repository
anywhere you have access to. Sharing it with only some people means
as giving them read or write access to the repository directory.

The following assumes you have a NERSC account and want to create a private
repository on Franklin. To apply this to a different machine just replace
\texttt{franklin.nersc.gov} with the machine you want to put the repository on.

\begin{enumerate}
\item SSH to \texttt{franklin.nersc.gov}, or wherever you want your
  repository
  \begin{verbatim}
    $ ssh username@franklin.nersc.gov
  \end{verbatim}
\item Create a ``bare'' Git repository by cloning a repository with the \texttt{--bare} option:
  \begin{verbatim}
    $ cd ~
    $ git clone --bare git@github.com:bendudson/BOUT.git  bout_private
  \end{verbatim}
  where you can replace \texttt{git@github.com:bendudson/BOUT.git} with any other repository you can access.
  \texttt{bout\_private} will be the name of the directory which will be created.
  This will make a repository without a working version. This means you can't modify the
  code in it directly, but can pull and push changes to it. If you want to work on the code on Franklin,
  make a clone of your private repository:
  \begin{verbatim}
    $ git clone bout_private bout
  \end{verbatim}
  which creates a repository \texttt{bout} from your private repository. Running \texttt{git pull} and
  \texttt{git push} from within this new repository will exchange patches with your \texttt{bout\_private}
  repository.
\item You can now clone, pull and push changes to your private repository over SSH e.g.
  \begin{verbatim}
    $ git clone username@franklin.nersc.gov:bout_private
  \end{verbatim}
\item To keep your private repository up to date you may want to pull changes from
  github into your private repository. To do this, you need to use a third repository. Log into
  Franklin again:
  \begin{verbatim}
    $ cd ~
    $ git clone bout_private bout_tmp
  \end{verbatim}
  This creates a repository \texttt{bout\_tmp} from your private repository. Now cd to the new directory
  and pull the latest changes from github:
  \begin{verbatim}
    $ cd bout_tmp
    $ git pull git://github.com/bendudson/BOUT.git
  \end{verbatim}
  Note: You should be able to access this repository from Franklin, but if not then see the previous subsection
  for how to access github from behind a firewall.
\item
  This pull might result in some conflicts which need to be resolved. If so, git will
  tell you, and running
  \begin{verbatim}
    $ git status
  \end{verbatim}
  will give a list of files which need to be resolved. Edit each of the files listed, and when you're happy 
  commit the changes
  \begin{verbatim}
    $ git commit -a
  \end{verbatim}
\item Your \texttt{bout\_tmp} directory now contains a merge of your private repository and the repository
  on github. To update your private repository, just push the changes back:
  \begin{verbatim}
    $ git push
  \end{verbatim}
  You can now delete the \texttt{bout\_tmp} repository if you want.
\end{enumerate}


\subsection{House rules}

BOUT++ consists of about 60,000 lines of C/C++
%
\footnote{generated using Al Danial's cloc}
%,
along with 18,500 lines of IDL and 12,000 of Python. Of this, about
40,000 lines is the core BOUT++ code, and the remainder a mix of pre-
and post-processors, and physics modules. As production codes go, this
is not particularly huge, but it is definitely large enough that
keeping the code `clean' and understandable is necessary. This is
vital if many people are going to work on the code, and also greatly
helps code debugging and verification. There are therefore a few house
rules to keep in mind when modifying the BOUT++ code.

When modifying the core BOUT++ code, please keep in mind that this portion of the code
is intended to be general (i.e. independent of any particular physical system of equations),
and to be used by a wide range of users. Making code clear is also more important
in this section than the physics model since the number of developers is potentially
much greater. 

Here are some rules for editing the core BOUT++ code:
\begin{itemize}
\item \index{Fortran} {\bf NO FORTRAN}. EVER. Though it may be tempting for scientific programmers to use
a little FORTRAN now and then, please please don't put any into BOUT++. 
Use of FORTRAN, particularly when mixed with C/C++, is the cause of many problems in
porting and modifying codes. 
\item If a feature is needed to study a particular system, only include it in the
core code if it is more generally applicable, or cannot be put into the physics module.
\end{itemize}

\subsection{Coding conventions}

See CONTRIBUTING.md for guidelines on naming and other coding conventions used
within BOUT++.

\section{Code layout}

BOUT++ is organised into classes and groups of functions which operate on them: 
It's not purely object-oriented, but takes advantage of many of C++'s object-oriented features. 

Figure~\ref{fig:layout1} shows the most important parts of BOUT++ and how they fit together.
\begin{figure}[htbp!]
\centering
\includegraphics[width=0.7\paperwidth, keepaspectratio]{figs/layout1.pdf}
\caption{Overview of BOUT++ control flow during initialisation (red), and running (blue)}
\label{fig:layout1}
\end{figure}
The initialisation process is shown in red: basic information is first read from the grid
file (e.g. size of the grid, topology etc.), then the user-supplied initialisation
code is called. This code can read other variables from the grid, and makes at least
one call
to \code{bout\_solve} to specify a variable to be evolved. The main thing \code{bout\_solve}
does is to add these variables to the solver. 

The process of running a timestep is shown in blue in figure~\ref{fig:layout1}:
The main loop calls the solver, which in turn calls PVODE. To evolve the system
PVODE makes calls to the RHS function inside solver. This moves data between PVODE
and BOUT++, and calls the user-supplied \code{physics\_run} code to calculate
time-derivatives. Much of the work calculating time-derivatives involves differential
operators.

Calculation of the RHS function \code{physics\_run}, and handling of data
in BOUT++ involves many different components. Figure~\ref{fig:layout2}
shows (most) of the classes and functions involved, and the relationships
between them. Some thought was put into how this should be organised, but
it has also changed over time, so some parts could be cleaner.
\begin{figure}[htbp!]
\centering
\includegraphics[width=0.6\paperwidth, keepaspectratio]{figs/layout2.pdf}
\caption{Relationship between important classes and functions used in calculating the RHS function}
\label{fig:layout2}
\end{figure}

\subsection{Directories}

The source code for the core of BOUT++ is divided into
include files (which can be used in physics models) in 
\file{bout++/include}, and source code and low-level includes
in \file{bout++/src}. Many parts of the code are defined by their
interface, and can have multiple different implementations. An example
is the time-integration solvers: many different implementations are available,
some of which use external libraries, but all have the same interface and can
be used interchangeably. This is reflected in the directory structure
inside \file{bout++/src}. A common pattern is
to store individual implementations of an interface
in a subdirectory called \texttt{impls}. 
\begin{verbatim}
include/foo.hxx
src/.../foo.cxx
src/.../foo_factory.hxx
src/.../foo_factory.cxx
src/.../impls/one/one.hxx
src/.../impls/one/one.cxx
\end{verbatim}
where \texttt{foo.hxx} defines the interface, \texttt{foo.cxx} implements common functions
used in several implementations. \texttt{foo\_factory} creates new implementations, and is
the only file which includes all the implementations. Individual implementations
are stored in their own subdirectories of \texttt{impls}. Components which follow this pattern
include \texttt{fileio} formats, \texttt{invert/laplace} and \texttt{invert/parderiv} 
inversion codes, \texttt{mesh}, and \texttt{solver}.

The current source code files are:
\begin{itemize}
\item \file{bout++.cxx} : Main file which initialises, runs and finalises
  BOUT++. Currently contains a \code{main()} function, though this is
  being removed shortly.
\item field
  \begin{itemize}
  \item \index{Field3D} \file{field2d.cxx} implements the \code{Field2D} class. This is a
    scalar field which varies only in $x$ and $y$ and is used for things
    like metric tensor components and initial profiles. It supplies lots
    of overloaded operators and functions on these objects.
  \item \file{field3d.cxx} implements the \code{Field3D} class, which varies 
    in $x$, $y$ and $z$. Since these handle a lot more memory than Field2D
    objects, the memory management is more complicated and includes reference
    counting. See section~\ref{sec:memorymanage} for more details.
  \item \file{field\_data.cxx} Implements some functions in the \code{FieldData} class. This is a mainly pure virtual interface class which is inherited by \code{Field2D} and \code{Field3D}.
  \item \file{fieldperp.cxx} implements a \code{FieldPerp} class to store
    slices perpendicular to the magnetic field i.e. they are a function of
    $x$ and $z$ only. This is mainly used for Laplacian inversion routines,
    and needs to be integrated with the other fields better.
  \item \file{initialprofiles.cxx} routines to set the initial values of
    fields when a simulation first starts. Reads settings from the option
    file based on the name of the variable.
  \item \file{vecops.cxx} a collection of function to operate on vectors. 
    Contains things like \code{Grad}, \code{Div} and \code{Curl}, and uses
    a combination of field differential operators (in \file{difops.cxx}) and
    metric tensor components (in \code{Mesh}).
  \item \file{vector2d.cxx} implements the \code{Vector2D} class, which uses
    a \code{Field2D} object for each of its 3 components. Overloads operators 
    to supply things like dot and cross products.
  \item \file{vector3d.cxx} implements \code{Vector3D} by using a
    \code{Field3D} object for each component.
  \item \file{where.cxx} supplies functions for choosing between values
    based on selection criteria.
  \end{itemize}
\item fileio
  \begin{itemize}
  \item \file{datafile.cxx} supplies an abstract \code{DataFile} interface
    for data input and output. Handles the conversion of data in fields
    and vectors into blocks of data which are then sent to a specific file
    format.
  \item \file{formatfactory.cxx}
  \item \file{formatfactory.hxx}
  \item impls
    \begin{itemize}
    \item \file{emptyformat.hxx}
    \item hdf5
      \begin{itemize}
      \item \file{h5\_format.cxx} implements an interface to the HDF5 library
      \item \file{h5\_format.hxx}
      \end{itemize}
    \item netcdf
      \begin{itemize}
      \item \file{nc\_format.cxx} implements an interface to the NetCDF-4 library
      \item \file{nc\_format.hxx}
      \end{itemize}
    \item netcdf4
      \begin{itemize}
      \item \file{ncxx4.cxx} implements an interface to the NetCDF-4
        library using the C++ API
      \item \file{ncxx4.hxx}
      \end{itemize}
    \item pnetcdf
      \begin{itemize}
        \item \file{pnetcdf.cxx} Parallel NetCDF interface
        \item \file{pnetcdf.hxx}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item invert
  \begin{itemize}
  \item \file{fft\_fftw.cxx} implements the \code{fft.hxx} interface by calling
    the Fastest Fourier Transform in the West (FFTW) library.
  \item \file{full\_gmres.cxx}
  \item \file{inverter.cxx} is a \code{FieldPerp} inversion class currently
    under development. It is intended to provide a way to solve nonlinear
    problems using a GMRES iterative method.
  \item \file{invert\_gmres.cxx}
  
  \item \file{invert\_laplace\_gmres.cxx} inherits the \code{Inverter} class
    and will solve more general Laplacian problems, using the
    \code{invert\_laplace} routines as preconditioners.
  \end{itemize}
\item invert / laplace
  \begin{itemize}
  \item \file{invert\_laplace.cxx} uses Fourier decomposition in $z$ combined
    with tri- and band-diagonal solvers in $x$ to solve Laplacian problems.
  \item \file{laplacefactory.hxx}
  \item \file{laplacefactory.cxx}
  \item impls
    \begin{itemize}
    \item serial\_tri
      \begin{itemize}
      \item \file{serial\_tri.hxx}
      \item \file{serial\_tri.cxx}
      \end{itemize}
    \item serial\_band
      \begin{itemize}
      \item \file{serial\_band.hxx}
      \item \file{serial\_band.cxx}
      \end{itemize}
    \item spt
      \begin{itemize}
      \item \file{spt.hxx}
      \item \file{spt.cxx}
      \end{itemize}
    \item pdd
      \begin{itemize}
      \item \file{pdd.hxx}
      \item \file{pdd.cxx}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item invert / parderiv
  \begin{itemize}
  \item \file{invert\_parderiv.cxx} inverts a problem involving only parallel
    $y$ derivatives. Intended for use in some preconditioners.
  \item \file{parderiv\_factory.hxx}
  \item \file{parderiv\_factory.cxx}
  \item impls
    \begin{itemize}
    \item serial
      \begin{itemize}
      \item \file{serial.cxx}
      \item \file{serial.hxx}
      \end{itemize}
    \item cyclic
      \begin{itemize}
      \item \file{cyclic.cxx}
      \item \file{cyclic.hxx}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item \file{lapack\_routines.cxx} supplies an interface to the LAPACK linear
  solvers, which are used by the \code{invert\_laplace} routines.
\item mesh
  \begin{itemize}
  \item \file{boundary\_factory.cxx} creates boundary condition operators
    which can then be applied to fields. Described in
    section~\ref{sec:BoundaryFactory}.
  \item \file{boundary\_region.cxx} implements a way to describe and iterate
    over boundary regions. Created by the mesh, and then used by boundary
    conditions. See section~\ref{sec:BoundaryRegion} for more details.
  \item \file{boundary\_standard.cxx} implements some standard boundary
    operations and modifiers such as \code{Neumann} and \code{Dirichlet}.
  \item \file{difops.cxx} is a collection of differential operators on scalar
    fields. It uses the differential methods in \file{derivs.cxx} and the
    metric tensor components in \code{Mesh} to compute operators.
  \item \file{grid.cxx} contains some routines which are used by the \code{Mesh}
    to read data. 
  \item \file{interpolation.cxx} contains functions for interpolating fields
  \item \file{mesh.cxx} is the base class for the \code{Mesh} object. Contains
    routines useful for all \code{Mesh} implementations.
  \item impls
    \begin{itemize}
    \item \file{domain.cxx}
    \item \file{domain.hxx}
    \item \file{partition.cxx}
    \item \file{partition.hxx}
    \item bout
      \begin{itemize}
      \item \file{boutmesh.cxx} implements a mesh interface which is compatible
	with BOUT grid files.
      \item \file{boutmesh.hxx}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item physics
  \begin{itemize}
  \item \file{gyro\_average.cxx} gyro-averaging operators
  \item \file{smoothing.cxx} provides smoothing routines on scalar fields
  \item \file{sourcex.cxx} contains some useful routines for creating
    sources and sinks in physics equations.
  \end{itemize}
\item precon
  \begin{itemize}
  \item \file{jstruc.cxx} is an experimental code for preconditioning using
    PETSc
  \end{itemize}
\item solver
  \begin{itemize}
  \item \file{solver.cxx} is the interface for all solvers 
  \item \file{solverfactory.cxx} creates solver objects
  \item \file{solverfactory.hxx}
  \item impls
    \begin{itemize}
    \item cvode
      \begin{itemize}
      \item \file{cvode.cxx} is the implementation of \code{Solver} which
        interfaces with the SUNDIALS CVODE library.
      \item \file{cvode.hxx}
      \end{itemize}
    \item ida
      \begin{itemize}
      \item \file{ida.cxx} is the implementation which interfaces with the
        SUNDIALS IDA library
      \item \file{ida.hxx}
      \end{itemize}
    \item petsc
      \begin{itemize}
      \item \file{petsc.cxx} is the interface to the PETSc time integration
        routines
      \item \file{petsc.hxx}
      \end{itemize}
    \item pvode
      \begin{itemize}
      \item \file{pvode.cxx} interfaces with the 1998 (pre-SUNDIALS) version
        of PVODE (which became CVODE).
      \item \file{pvode.hxx}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item sys
  \begin{itemize}
  \item \file{boutcomm.cxx}
  \item \file{boutexception.cxx} is an exception class which are used
    for error handling
  \item \file{comm\_group.cxx} provides routines for non-blocking collective 
    MPI operations. These are not available in MPI-2, though are planned for
    MPI-3.
  \item \file{dcomplex.cxx} provides a \code{dcomplex} complex type. It is here
    because the original type \code{real} conflicted with the STL definition.
    This could probably be replaced with the STL implementation now.
  \item \file{derivs.cxx} contains basic derivative methods such as
    upwinding, central difference and WENO methods. These are then
    used by \file{difops.cxx}. Details are given in
    section~\ref{sec:derivatives}.
  \item \file{msg\_stack.cxx} is part of the error handling system. It maintains
    a stack of messages which can be pushed onto the stack at the start of 
    a function, then removed (popped) at the end. If an error occurs or 
    a segmentation fault is caught then this stack is printed out and can
    help to find errors.
  \item \file{options.cxx} provides an interface to the BOUT.inp option file
    and the command-line options.
  \item \file{optionsreader.cxx}
  \item \file{output.cxx}
  \item \file{range.cxx} Provides the RangeIterator class, used to iterate over a set
    of ranges. Described in section~\ref{sec:rangeiterator}
  \item \file{stencils.cxx} contains methods to operate on stencils which are
    used by differential methods. 
  \item \file{timer.cxx} a class for timing parts of the code like communications
    and file I/O. Described in section~\ref{sec:timerclass}
  \item \file{utils.cxx} contains miscellaneous small useful routines
    such as allocating and freeing arrays.
  \item options
    \begin{itemize}
    \item \file{optionparser.hxx}
    \item \file{options\_ini.cxx}
    \item \file{options\_ini.hxx}
    \end{itemize}
  \end{itemize}
\end{itemize}

\section{Data types}

The classes outlines in red in figure~\ref{fig:layout2} are data types 
currently implemented in BOUT++. 

\subsection{\code{FieldData}}
\index{FieldData}
All BOUT++ data types implement a standard interface for accessing their
data, which is then used in communication and file I/O code. This interface
is in \file{src/field/field\_data.hxx}. The mandatory (pure virtual) functions are:
\begin{lstlisting}
bool isReal(); // Returns true if field consists of real values
bool is3D() const;   // True if variable is 3D
  
int byteSize() const; // Number of bytes for a single point
int realSize() const; // Number of reals (not implemented if not real)
\end{lstlisting}

To support file I/O there are also some additional functions which may be implemented.
A code can check if they are implemented by calling \code{ioSupport}. If one of them
is implemented then they all should be.
\begin{lstlisting}
bool  ioSupport();  // Return true if these functions are implemented
const string getSuffix(int component) const; // For vectors e.g. "_x"
void* getMark() const; // Store current settings (e.g. co/contra-variant)
void  setMark(void *setting); // Return to the stored settings
BoutReal* getData(int component); 
void  zeroComponent(int component); // Set a component to zero
\end{lstlisting}  

For twist-shift conditions, the optional function \code{shiftZ} is called in the communication
routines.
\begin{lstlisting}
void shiftZ(int jx, int jy, double zangle);
\end{lstlisting}

\subsection{\code{Field}}
\index{Field}
The two main types are \code{Field2D}, and \code{Field3D}. Their main functions
are to provide an easy way to manipulate data; they take care of all memory management,
and most looping over grid-points in algebraic expressions. The 2D field implementation
is relatively simple, but more optimisations are used in the 3D field implementation
because they are much larger (factor of $\sim 100$).

To handle time-derivatives, and enable expressions to be written in the
following form:
\begin{lstlisting}
ddt(Ni) = -b0xGrad_dot_Grad(phi, Ni);
\end{lstlisting}
fields (and vectors, see below) have a function:
\begin{lstlisting}
Field3D* timeDeriv();
\end{lstlisting}
which returns a pointer to the field holding the time-derivative
of this variable. This function ensures that this field is unique
using a singleton pattern.

\subsection{\code{Vector}}
\index{Vector}
Vector classes build on the field classes, just using a field to represent
each component. 

To handle time-derivatives of vectors, some care is needed to ensure that
the time-derivative of each vector component points to the same
field as the corresponding component of the time-derivative of the vector:
\begin{lstlisting}
ddt(v.x) = ddt(v).x
\end{lstlisting}

\subsection{\code{dcomplex}}
\index{dcomplex}
Several parts of the BOUT++ code involve FFTs and are therefore much easier to
write using complex numbers. Unfortunately, the C++ complex library also tries
to define a \code{real} type, which is already defined by PVODE. Several
work-arounds were tried, some of which worked on some systems, but
it was easier in the end to just implement a new class \code{dcomplex} to
handle complex numbers.

\subsection{Memory management}
\label{sec:memorymanage}

This code has been thoroughly tested/debugged, and should only be altered
with great care, since just about every other part of BOUT++ depends on this code
working correctly. Two optimisations used in the data objects to speed up code execution
are memory recycling, which eliminates allocation and freeing of memory; and copy-on-change,
which minimises unnecessary copying of data.

Both of these optimisations are done ``behind the scenes'', hidden from the remainder
of the code, and are illustrated in figure~\ref{fig:memory}:
\begin{figure}[htb!]
\centering
\includegraphics[scale=0.75]{figs/memory.pdf}
\caption{Memory handling in BOUT++. Memory allocation and freeing is eliminated by recycling memory blocks, and assignments without changes (\code{A = B}) do not result in copying data, only pointers to the data. Both these optimisations are handled internally, and are invisible to the programmer.}
\label{fig:memory}
\end{figure}
The objects (A,B,C) accessed by the user in operations
discussed in the previous section act as an interface to underlying data (a,b). 
Memory recycling can be used because all the scalar fields are the same size (and vector fields are
implemented as a set of 3 scalar fields). Each class implements a global stack of available
memory blocks. When an object is assigned a value, it attempts to grab one of these memory blocks,
and if none are available then a new block is allocated. 
When an object is destroyed, its memory block is not freed, but is put onto the
stack. Since the evaluation of the time-derivatives involves the same set of operations each time, this system
means that memory is only allocated the first time the time-derivatives are calculated, after which the same 
memory blocks are re-used. This eliminates the often slow system calls needed to allocate and free memory,
replacing them with fast pointer manipulation. 

Copy-on-change (reference counting) further reduces memory useage and unnecessary copying of data. 
When one field is set equal to another (e.g. \code{Field3D A = B} in figure~\ref{fig:memory}), no 
data is copied, only the reference to the underlying data (in this case both A and B point to data block a). 
Only when one of these objects is modified is a second memory block used to store the different value. 
This is particularly useful when returning objects from a routine. Usually this would
involve copying data from one object to another, and then destroying the original copy. Using
reference counting this copying is eliminated.

\note{For debugging and Valgrind output, it can be useful to disable
this memory block handling. To do this, add \code{-DDISABLE\_FREELIST} to the
compile flags}

\section{Derivatives}
\label{sec:derivatives}

This is probably the part of the code most people will want to alter, and is
in \texttt{bout++/src/sys/derivs.cxx}. The main
task of this module is to map functions on fields like \code{DDX}
to direction-independent differential methods on stencils such as
$4^{th}$-order central differencing. This mapping depends on global
settings in \file{BOUT.inp} and is illustrated in figure~\ref{fig:diffOverview}.
\begin{figure}[htb!]
\centering
\includegraphics[scale=0.75]{figs/diffOverview.pdf}
\caption{Overview of \code{derivs} module, mapping derivative functions on fields to direction-independent differential methods}
\label{fig:diffOverview}
\end{figure}

Four kinds of differencing methods are supported
\begin{enumerate}
\item First derivative \code{DDX}, \code{DDY}, \code{DDZ} \\
  Central differencing type schemes for first-order derivatives
\item Second derivatives \code{D2DX2}, \code{D2DZ2}, \code{D2DZ2} \\
  Central differencing second derivatives e.g. for $\nabla^2$
\item Upwinding \code{VDDX}, \code{VDDY}, \code{VDDZ} \\
   Terms like $\mathbf{v}\cdot\nabla$
\item Flux methods \code{FDDX}, \code{FDDY}, \code{FDDZ} \\
  Flux conserving, limiting methods for terms like $\nabla\cdot\left(\mathbf{v}f\right)$
\end{enumerate}

The differencing methods themselves are independent on direction, and have
types defined in \texttt{derivs.cxx}
\begin{lstlisting}
typedef BoutReal (*deriv_func)(stencil &); // f
typedef BoutReal (*upwind_func)(stencil &, stencil &); // v, f
\end{lstlisting}
These operate on \code{stencil} objects. This class is in \file{stencils.hxx}
\index{stencil}
\begin{lstlisting}
class stencil {
  public:
    int jx, jy, jz;  // Central location
    BoutReal c, p, m, pp, mm; // stencil 2 each side of the centre
    Overloaded operators
      =,+,-,*,/
    Functions
      min, max, abs
};
\end{lstlisting}
The main purpose of this class is to store a 5-element stencil. To simplify some code
this class also has a bunch of overloaded operators on BoutReals and other stencil objects. 
There are also some functions to calculate things like absolute, minimum, and maximum
values.

\subsection{Lookup tables}

To convert between short variable names (``C2''), long descriptions 
(``2nd order Central Differencing''), \texttt{DIFF\_METHOD} enums used to specify methods
at runtime (DIFF\_C2, defined in \texttt{bout\_types.hxx}), and function pointers
(\texttt{DDX\_C2}), taking into account whether
variables are shifted or not, BOUT++ uses a set of lookup tables.

To find function pointers, tables of the following type are used: \index{DiffLookup}
\begin{lstlisting}
/// Translate between DIFF_METHOD codes, and functions
struct DiffLookup {
  DIFF_METHOD method;
  deriv_func func;     // Single-argument differencing function
  upwind_func up_func; // Upwinding function
};
\end{lstlisting}
Because the \texttt{DiffLookup} type contains a \texttt{deriv\_func} and
\texttt{upwind\_func} pointer, it is used for all function lookup tables. 
There is a separate table for each type of differencing method, so for example
the table of non-staggered upwinding methods is
\begin{lstlisting}
/// Upwinding functions lookup table
static DiffLookup UpwindTable[] = { {DIFF_U1, NULL, VDDX_U1},
				    {DIFF_C2, NULL, VDDX_C2},
				    {DIFF_U4, NULL, VDDX_U4},
				    {DIFF_W3, NULL, VDDX_WENO3},
				    {DIFF_C4, NULL, VDDX_C4},
				    {DIFF_DEFAULT}};
\end{lstlisting}
The \texttt{DIFF\_DEFAULT} at the end is used to terminate the array. 
These tables are used by functions
\begin{lstlisting}
deriv_func lookupFunc(DiffLookup* table, DIFF_METHOD method);
upwind_func lookupUpwindFunc(DiffLookup* table, DIFF_METHOD method);
\end{lstlisting}
which return the function pointer corresponding to the given method. If the
method isn't in the table, then the first entry in the table is used.
These functions can be used at run-time to allow a user to specify the method
to use for specific operators. 

When reading settings from the input file, they are specified as short
strings like ``C2'', and a longer description
of the method chosen should be written to the output log. To do this, 
there is a name lookup table: \index{DiffNameLookup}
\begin{lstlisting}
/// Translate between short names, long names and DIFF_METHOD codes
struct DiffNameLookup {
  DIFF_METHOD method;
  const char* label; // Short name
  const char* name;  // Long name
};

static DiffNameLookup DiffNameTable[] = { 
  {DIFF_U1, "U1", "First order upwinding"},
  {DIFF_C2, "C2", "Second order central"},
  {DIFF_W2, "W2", "Second order WENO"},
  {DIFF_W3, "W3", "Third order WENO"},
  {DIFF_C4, "C4", "Fourth order central"},
  {DIFF_U4, "U4", "Fourth order upwinding"},
  {DIFF_FFT, "FFT", "FFT"},
  {DIFF_DEFAULT}}; // Use to terminate the list
\end{lstlisting}

To search this table, there is the function
\begin{lstlisting}
DIFF_METHOD lookupFunc(DiffLookup *table, const string &label)
\end{lstlisting}

During initialisation, the lookup therefore works in two stages,
shown in figure~\ref{fig:diffLookup}. First the short description is turned into
a \texttt{DIFF\_METHOD} enum code, then this code is turned into a function pointer.
\begin{figure}[htb!]
\centering
\includegraphics[scale=0.75]{figs/diffLookup.pdf}
\caption{Lookup tables for mapping between differential method labels, codes, descriptions and function pointers}
\label{fig:diffLookup}
\end{figure}

\subsection{Staggered grids}
\index{staggered grids}
\note{This feature is currently very experimental, and doesn't appear to work as it should}

By default, all quantities in BOUT++ are defined at cell centre, and
all derivative methods map cell-centred quantities to cell centres.
Switching on staggered grid support in BOUT.inp:
\begin{verbatim}
StaggerGrids = true
\end{verbatim}
allows quantities to be defined on cell boundaries. Functions such as \code{DDX} now have to handle
all possible combinations of input and output locations, in addition to the possible
derivative methods. 

Several things are not currently implemented, which probably should be:
\begin{itemize}
\item Only 3D fields currently have a cell location attribute. The location (cell centre etc) of 2D fields is ignored at the moment. The rationale for this is that 2D fields are assumed to be slowly-varying equilibrium quantities for which it won't matter so much. Still, needs to be improved in future
\item Twist-shift and X shifting still treat all quantities as cell-centred.
\item No boundary condition functions yet account for cell location. 
\end{itemize}

Currently, BOUT++ does not support values at cell corners; values can
only be defined at cell centre, or at the lower X,Y, or Z boundaries. 
This is 

Once staggered grids are enabled, two types of stencil are needed: those
which map between the same cell location (e.g. cell-centred values to cell-centred values), and those which map to different locations (e.g. cell-centred to lower X).

\begin{figure}[htb!]
\centering
\includegraphics[scale=0.9]{figs/diffStencils.pdf}
\caption{Stencils with cell-centred (solid) and lower shifted values (open). Processor boundaries
marked by vertical dashed line}
\label{fig:diffStencils}
\end{figure}

Central differencing using 4-point stencil:
\begin{eqnarray*}
y &=& \left(9y_{-1/2} + 9y_{1/2} - y_{-3/2} - y_{3/2}\right) / 16 \\
\deriv{y}{x} &=& \left( 27y_{1/2} - 27y_{-1/2} - y_{3/2} + y_{-3/2}\right) / 24\Delta x \\
\frac{\partial^2 y}{\partial x^2} &=& \left(y_{3/2} + y_{-3/2} - y_{1/2} - y_{-1/2}\right) / 2\Delta x^2
\end{eqnarray*}

\note{What should the default cell location of a derivative be? Currently the default is to remain the same as without staggered grids. Setting \code{StaggerGrids = true} by itself has no effect - derivative output locations have to be explicitly set.}

\begin{table}[htbp!]
\caption{DDX actions depending on input and output locations. Uses first match.}
\label{tab:ddxloc}
\centering
\begin{tabular}[c]{c c | l}
\hline
Input & Output & Actions \\
\hline
\multicolumn{2}{c}{Same locations} & Central stencil \\
CENTRE & XLOW & Lower staggered stencil \\
XLOW & CENTRE & Upper staggered stencil \\
XLOW & Any & Staggered stencil to CENTRE, then interpolate \\
CENTRE & Any & Central stencil, then interpolate \\
Any & Any & Interpolate to centre, use central stencil, then interpolate \\
\hline
\end{tabular}
\end{table}

\section{Laplacian inversion}
\index{Laplacian}
\note{This part of the code needs some algorithm improvement (better parallel tridiagonal solver).}


The Laplacian inversion code solves the equation:
\[
d\nabla^2_\perp x + \frac{1}{c}\nabla_\perp c\cdot\nabla_\perp x + a x = b
\]
where $x$ and $b$ are 3D variables, whilst $a$, $c$ and $d$ are 2D variables.
Several different algorithms are implemented for Laplacian inversion, and
they differ between serial and parallel versions.
Serial inversion can currently either be done using a tridiagonal solver
(Thomas algorithm), or a band-solver (allowing $4^{th}$-order differencing).


To support multiple implementations, a base class \lstinline!Laplacian! is defined
in \file{include/invert\_laplace.hxx}. This defines a set of functions which all
implementations must provide:
\begin{lstlisting}
class Laplacian {
 public:
  virtual void setCoefA(const Field2D &val) = 0;
  virtual void setCoefC(const Field2D &val) = 0;
  virtual void setCoefD(const Field2D &val) = 0;
 
  virtual const FieldPerp solve(const FieldPerp &b) = 0;
}
\end{lstlisting}
At minimum, all implementations must provide a way to set coefficients, and
a solve function which operates on a single FieldPerp (X-Y) object at once.
Several other functions are also virtual, so default code exists but
can be overridden by an implementation.


For convenience, the \lstinline!Laplacian! base class also defines a function to
calculate coefficients in a Tridiagonal matrix
\begin{lstlisting}
  void tridagCoefs(int jx, int jy, int jz, dcomplex &a, dcomplex &b, dcomplex &c, const Field2D *ccoef = NULL, const Field2D *d=NULL);
\end{lstlisting}

For the user of the class, some static functions are defined:
\begin{lstlisting}
  static Laplacian* create(Options *opt = NULL);
  static Laplacian* defaultInstance();
\end{lstlisting}

The create function allows new Laplacian implementations to be created, based
on options. To use the options in the \texttt{[laplace]} section, just use the default:
\begin{lstlisting}
  Laplacian* lap = Laplacian::create();
\end{lstlisting}

The code for the \lstinline!Laplacian! base class is in \file{src/invert/laplace/invert\_laplace.cxx}. The actual creation of new Laplacian implementations is done in the \lstinline!LaplaceFactory! class, defined in \file{src/invert/laplace/laplacefactory.cxx}. This file includes all the headers for the implementations, and chooses which one to create based on the ``type'' setting in the input options. This factory therefore provides a single point of access to the underlying Laplacian inversion implementations.

Each of the implementations is in a subdirectory of \file{src/invert/laplace/impls} and is
discussed below.


\subsection{Serial tridiagonal solver}

This is the simplest implementation, and is in \file{src/invert/laplace/impls/serial\_tri/}

\subsection{Serial band solver}

This is band-solver which performs a $4^{th}$-order inversion. Currently this
is only available when \code{NXPE=1}; when more than one processor is used in $x$,
the Laplacian algorithm currently reverts to $3^{rd}$-order.

\subsection{SPT parallel tridiagonal}

This is a reference code which performs the same operations as the serial code.
To invert a single XZ slice (\lstinline!FieldPerp! object), data must pass
from the innermost processor (\lstinline!mesh->PE_XIND = 0!) to the outermost
\lstinline!mesh->PE_XIND = mesh->NXPE-1! and back again.

Some parallelism is achieved by running several inversions simultaneously,
so while processor 1 is inverting Y=0, processor 0 is starting on Y=1.
This works ok as long as the number of slices to be inverted is greater than
the number of X processors (\lstinline!MYSUB > mesh->NXPE!). If
\lstinline!MYSUB < mesh->NXPE! then
not all processors can be busy at once, and so efficiency will fall sharply.
Figure~\ref{fig:par_laplace} shows the useage of 4 processors inverting a set
of 3 poloidal slices
(i.e. MYSUB=3)
\begin{figure}[htbp!]
\centering
\includegraphics[width=0.5\paperwidth, keepaspectratio]{figs/par_laplace.pdf}
\caption{Parallel Laplacian inversion with MYSUB=3 on 4 processors. Red periods are where a processor is idle - in this case about 40\% of the time}
\label{fig:par_laplace}
\end{figure}

\subsection{PDD algorithm}

This is the Parallel Diagonally Dominant (PDD) algorithm. It's very fast, but
achieves this by neglecting some cross-processor terms. For ELM simulations, 
it has been found that these terms are important, so this method is not
usually used. 

\section{Mesh}
\index{Mesh}
The mesh is used in pretty much all parts of the code, and deals with 
things like the geometry of the mesh (metric tensors etc.), and how the
mesh is divided between processors (communications). The Mesh class
(\file{include/mesh.hxx}) defines an interface, and there are currently
two implementations:
\begin{itemize}
\item \lstinline!BoutMesh! (\file{src/mesh/boutmesh.cxx}) \index{BoutMesh} which is backwards compatible
  with the BOUT and BOUT-06 codes. This is a logically rectangular mesh so
  the number of radial points (x) can't change in the poloidal direction (y). 
  
\item \lstinline!QuiltMesh! (\file{src/mesh/quiltmesh.cxx}) \index{QuiltMesh} is a more general mesh under development
  (i.e. {\bf not} recommended except for testing). The primary advantage is that
  it allows the number of points in x to vary between regions so the number of radial
  grid points in the core no longer needs to be the same as the number in the private
  flux regions.
\end{itemize}

\subsection{Grid data sources}
\index{GridDataSource}

All data sources inherit from \lstinline!GridDataSource!, defined in \file{grid.hxx} at line
43. They must supply a method to test if a variable exists:
\begin{lstlisting}[firstnumber=47]
bool GridDataSource::hasVar(const char *name);
\end{lstlisting}
a method to get the size of the variable
\begin{lstlisting}[firstnumber=49]
vector<int> GridDataSource::getSize(const char *name);
\end{lstlisting}
To fetch data, first the (x,y,z) origin must be set:
\begin{lstlisting}[firstnumber=52]
bool GridDataSource::setOrigin(int x = 0, int y = 0, int z = 0);
\end{lstlisting}
and then use methods to fetch integers or reals:
\begin{lstlisting}[firstnumber=52]
bool GridDataSource::fetch(int *var, const string &name, int lx = 1, int ly = 0, int lz = 0);
bool GridDataSource::fetch(BoutReal *var, const string &name, int lx = 1, int ly = 0, int lz = 0);
\end{lstlisting}

In addition, GridDataSource implementations can have methods which should be called
before and after variables are accessed:
\begin{lstlisting}[firstnumber=52]
void GridDataSource::open(const char *name = NULL);
void GridDataSource::close();
\end{lstlisting}

\subsection{Loading a mesh}

To load in a mesh from a file or other source, there are the commands:
\begin{lstlisting}
int addSource(GridDataSource);   // Add a data source
int load();                      // Load from added data sources
int load(GridDataSource);        // Load from specified data source
\end{lstlisting}
all of which return an error code (0 if successful). 
\code{addSource} is used to add a set of input data sources which
inherit from \lstinline!GridDataSource!. \lstinline!load()! loads the mesh
from these sources, querying each data source in turn for the required
variables (in the order in which they were added). \lstinline!load(GridDataSource)!
loads the mesh from only the supplied data source.

In \file{bout++.cxx}, this is used to initialise the mesh:
\begin{lstlisting}
mesh->addSource(new GridFile(data_format(grid_name), grid_name));
if(mesh->load()) {
  output << "Failed to read grid. Aborting\n";
  return 1;
}
\end{lstlisting}
which creates a \code{GridFile} object based on the data format of 
the grid file name, then adds that as a source of data for Mesh.

For post-processing of the results, it's useful to have 
mesh quantities in the dump files along with the results. To do this,
there's the function
\begin{lstlisting}
void outputVars(Datafile &file); // Add mesh vars to file
\end{lstlisting}
which is called during BOUT++ initialisation.

\subsubsection{Implementation: BoutMesh}

BoutMesh class uses the BOUT indices (which trace back to UEDGE):
\begin{lstlisting}
int ixseps1, ixseps2, jyseps1_1, jyseps2_1, jyseps1_2, jyseps2_2;
\end{lstlisting}
\code{ixseps1} and \code{ixseps2} give the X location of the separatrices,
and are equal in the case of single-null configurations. The indexing
is such that all points \code{0 <= x < ixseps1} are inside the separatrix,
whilst \code{ixseps1 <= x < ngx} are outside.

\subsubsection{Implementation: QuiltMesh}





\subsection{Index ranges}

The Mesh class includes several public members which describe the
size of the mesh, and are used all over BOUT++ to loop over variables:
\begin{lstlisting}
/// Size of the mesh on this processor including guard/boundary cells
int ngx, ngy, ngz;  
/// Local ranges of data (inclusive), excluding guard cells
int xstart, xend, ystart, yend;
\end{lstlisting}

\subsection{Getting data}

The \code{load()} code above needs to read data for the mesh, and physics
codes usually need to read their initial profiles during initialisation.
To do this, Mesh provides an overloaded function \code{get}:
\begin{lstlisting}
int get(var, const char *name); // Request data from mesh file
\end{lstlisting}
where \code{var} can be just about any BOUT++ datatype (\code{Field2D},
\code{Vector3D} etc.). 

\subsubsection{Implementation: BoutMesh}

For integers and BoutReals, the implementation is fairly trivial. Uses
the Mesh protected functions to find a data source and read data from it.
\begin{lstlisting}
GridDataSource* s = findSource(name);  // Find a source of data
s->open(name);                          // Open the source
bool success = s->fetch(&ival, name);   // Get the data
s->close();                             // Close the source
\end{lstlisting}

To read 2D and 3D fields, the branch-cuts need to be taken into account.

\subsection{Communications}
\index{communication}

The most common type of communication is to just exchange all
guard cells with neighboring processors. Mesh provides the following
commands for doing this:
\begin{lstlisting}
int communicate(FieldData, ...); // Communicate one or more fields
int communicate(FieldGroup);     // Communicate a group of fields
int communicate(FieldData);      // Returns error code
comm_handle send(FieldGroup);    // Send data
int wait(comm_handle);           // Receive data
\end{lstlisting}
\code{communicate(FieldData)} can (currently) be used to communicate
up to 4 variables together, and makes the code quite clear. For example in
\file{examples/DriftInstability/2fluid.cxx} around line 360:
\begin{lstlisting}
// Need to communicate jpar
mesh->communicate(jpar);
\end{lstlisting}
Since this uses the \code{FieldData} interface like Datafile, this can
be used to communicate all BOUT++ field data types. The limit of 4 is
because the C-style \code{varargs} system doesn't work with ``non POD''
variables, i.e. classes. To communicate a larger number of variables,
create a \code{FieldGroup} object to group fields together, then communicate
them all together:
\begin{lstlisting}
FieldGroup comgrp;  // Group of variables for communication
Field3D P;
Vector3D V;

comgrp.add(P); // Add the variables
comgrp.add(V); // Usually done in physics_init

mesh->communicate(comgrp); // Communicate in physics_run
\end{lstlisting}

If you want to overlap communications with calculations then
use the \code{send} and \code{wait} functions instead of \code{communicate}.
\begin{lstlisting}
comm_handle ch = mesh->send(comgrp); // Start the communications
// Calculations which don't need variables in comgrp
wait(ch); // Wait for all communications to finish
\end{lstlisting}

\subsubsection{Implementation: BoutMesh}

In BoutMesh, the communication is controlled by the variables
\begin{lstlisting}
int UDATA_INDEST, UDATA_OUTDEST, UDATA_XSPLIT;
int DDATA_INDEST, DDATA_OUTDEST, DDATA_XSPLIT;
int IDATA_DEST, ODATA_DEST;
\end{lstlisting}
In the Y direction, each boundary region ({\bf U}p and {\bf D}own in Y) 
can be split into two, with \code{0 <= x < UDATA\_XSPLIT} going to
the processor index \code{UDATA\_INDEST}, and \code{UDATA\_INDEST <= x < ngx}
going to \code{UDATA\_OUTDEST}. Similarly for the Down boundary.
Since there are no branch-cuts in the X direction, there is just one
destination for the {\bf I}nner and {\bf O}uter boundaries.
In all cases a negative processor number means that there's a domain boundary.

\subsection{X communications}

For parallel Laplacian inversions, communication is needed in the X
direction only, and involves quantities which are not in Fields.

\begin{lstlisting}
bool firstX();  // True if at the inner X boundary
bool lastX();   // True if at the outer X boundary
int NXPE, PE_XIND; // Number of processors in X, and X processor index
int sendXOut(BoutReal *buffer, int size, int tag);
sendXIn(BoutReal *buffer, int size, int tag);
comm_handle irecvXOut(BoutReal *buffer, int size, int tag);
comm_handle irecvXIn(BoutReal *buffer, int size, int tag);
\end{lstlisting}

The variables \code{NXPE} and \code{PE\_XIND} shouldn't really be there,
but are currently needed because the SPT algorithm in \file{invert\_laplace.cxx}
needs to know when it's going to be next and so keep track of which processor
number is currently working. This logic to pass a problem along a chain in
X should really be moved into Mesh.

\subsection{Y-Z surface communications}

Some operations (like parallel inversions in \texttt{bout++/src/invert/invert\_parderiv.cxx}) need to be performed on
Y-Z surfaces, i.e. slices at constant X. This needs to be able to
handle open and closed surfaces, and that closed surfaces may need a 
shift in the Z direction to match one end onto the other (a twist-shift
condition).

The simplest operation is to average a quantity over Y:
\begin{lstlisting}
const Field2D averageY(const Field2D &f); // Average in Y
\end{lstlisting}
Currently this is only implemented for 2D fields. More generally a 
set of FieldData objects could be used.

To test if a particular surface is closed, there is the function
\begin{lstlisting}
bool surfaceClosed(int jx, BoutReal &ts); // Test if a surface is closed, and if so get the twist-shift angle
\end{lstlisting}

The most general way to access data on surfaces is to use an
iterator, which can be created using:
\begin{lstlisting}
SurfaceIter* iterateSurfaces();
\end{lstlisting}
This then allows looping over the surfaces in the usual way
\begin{lstlisting}
for(surf->first(); !surf->isDone(); surf->next()) {
  ...
}
\end{lstlisting}
{\bf NB}: This iterator splits the surfaces between processors, so each
individual processor will iterate over a different set of surfaces. This
is to allow automatic load balancing when gathering and scattering data
from an entire surface onto one processor using:
\begin{lstlisting}
surf->gather(FieldData, BoutReal *recvbuffer);
surf->scatter(BoutReal *sendbuffer, Field result);
\end{lstlisting}
The buffer is assumed to be large enough to hold all the data. To 
get the number of points in Y for this surface, use
\begin{lstlisting}
int ysize = surf->ysize();
\end{lstlisting}
To test if the surface is closed, there's the test
\begin{lstlisting}
bool surf->closed(BoutReal &ts)
\end{lstlisting}
which returns true if the surface is closed, along with the twist-shift angle.

\subsection{Initial profiles}
\index{variable initialisation}
The initial profiles code needs to construct a solution which is smooth
everywhere, with a form of perturbation specified in the input file
for each direction. In order to do this, it needs a continuous function
to use as an index. This is supplied by the functions:
\begin{lstlisting}
BoutReal GlobalX(int jx); // Continuous X index between 0 and 1
BoutReal GlobalY(int jy); // Continuous Y index (0 -> 1)
\end{lstlisting}
which take a local x or y index and return a globally continuous x or y
index.

\subsection{Differencing}

The mesh spacing is given by the public members
\begin{lstlisting}
// These used for differential operators 
Field2D dx, dy;
Field2D d2x, d2y;    // 2nd-order correction for non-uniform meshes		
BoutReal zlength, dz;    // Derived from options (in radians)
\end{lstlisting}

\subsection{Metrics}
\index{metric tensor}
The contravariant and covariant metric tensor components are
public members of \code{Mesh}: 
\begin{lstlisting}
// Contravariant metric tensor (g^{ij})
Field2D g11, g22, g33, g12, g13, g23; // These are read in grid.cxx

// Covariant metric tensor
Field2D g_11, g_22, g_33, g_12, g_13, g_23;

int calcCovariant();     // Invert contravatiant metric to get covariant
int calcContravariant(); // Invert covariant metric to get contravariant
\end{lstlisting}
If only one of these sets is modified by an external code, then
\code{calc\_covariant} and \code{calc\_contravariant} can be used
to calculate the other (uses Gauss-Jordan currently).

From the metric tensor components, Mesh calculates several other useful
quantities:
\begin{lstlisting}
int jacobian(); // Calculate J and Bxy
Field2D J; // Jacobian
Field2D Bxy; // Magnitude of B = nabla z times nabla x

/// Calculate differential geometry quantities from the metric tensor
int geometry();

// Christoffel symbol of the second kind (connection coefficients)
Field2D G1_11, G1_22, G1_33, G1_12, G1_13;
Field2D G2_11, G2_22, G2_33, G2_12, G2_23;
Field2D G3_11, G3_22, G3_33, G3_13, G3_23;
  
Field2D G1, G2, G3;
\end{lstlisting}

These quantities are public and accessible everywhere, but this is because
they are needed in a lot of the code. They shouldn't change
after initialisation, unless the physics model starts doing fancy things with
deforming meshes.

\subsection{Miscellaneous}

There are some public members of Mesh which are there for some specific
task and don't really go anywhere else (yet). 

To perform radial derivatives in tokamak geometry, interpolation is needed
in the Z direction. This is done by shifting in Z by a phase factor, performing
the derivatives, then shifting back. The following public variables are currently
used for this:
\begin{lstlisting}
bool ShiftXderivs; // Use shifted X derivatives
int  ShiftOrder;   // Order of shifted X derivative interpolation
Field2D zShift;    // Z shift for each point (radians)
  
Field2D ShiftTorsion; // d <pitch angle> / dx. Needed for vector differentials (Curl)
Field2D IntShiftTorsion; // Integrated shear (I in BOUT notation)
bool IncIntShear; // Include integrated shear (if shifting X)
\end{lstlisting}

\begin{lstlisting}
int  TwistOrder;   // Order of twist-shift interpolation
\end{lstlisting}
This determines what order method to use for the interpolation at the twist-shift
location, with \code{0} meaning FFT during communication. Since this must be 0 at the moment
it's fairly redundant and should be removed.

A (currently experimental) feature is 
\begin{lstlisting}
bool StaggerGrids;    ///< Enable staggered grids (Centre, Lower). Otherwise all vars are cell centred (default).
\end{lstlisting}

\section{Boundary conditions}
\label{sec:boundaries}
\index{boundary conditions}

The boundary condition system needs to be very flexible in order to handle:
\begin{itemize}
\item Meshes which can divide up the boundary into an arbitrary number
  of regions, giving each one a label. For example in BoutMesh 
  (specific to tokamaks), the boundary regions are labelled "core",
  "sol", "pf" and "target".
\item Each variable can have a different boundary condition in each region.
  It should be possible to have a global setting "all variables have dirichlet
  conditions on all boundaries", which is over-ridden by more specific settings
  such as "All variables have neumann conditions on the inner x boundaries", 
  and finally to "variable 'Ni' has laplacian boundary conditions in the
  'sol' regions"
\item Boundary conditions can be modified to be ``relaxing''. This means that
  rather than enforcing a strict boundary condition, it's a mixture of
  zero-gradient in the time-derivative combined with a damping (relaxation)
  towards the desired boundary condition. This can help improve the numerics
  of turbulence simulations.
\item Users should be able to implement their own boundary conditions,
  and add them to the system at run-time without modifying the core code.
\item After \code{physics\_init}, a boundary condition must be applied to
  the variables. During a simulation (at the end of \code{physics\_run}),
  boundary conditions need to be applied to the time-derivatives. The
  boundary system should ensure that these conditions are consistent.
\end{itemize}



\section{Variable initialisation}



\section{Solver}
\index{Solver}
The solver is the interface between BOUT++ and the time-integration code
such as SUNDIALS. All solvers implement the \code{Solver} class
interface (see \file{src/solver/generic\_solver.hxx}).

First all the fields which are to be evolved need to be added
to the solver. These are always done in pairs, the first
specifying the field, and the second the time-derivative:
\begin{lstlisting}
void add(Field2D &v, Field2D &F_v, const char* name);
\end{lstlisting}
This is normally called in the \code{physics\_init} initialisation routine.
Some solvers (e.g. IDA) can support constraints, which need to be added
in the same way as evolving fields:
\begin{lstlisting}
bool constraints();
void constraint(Field2D &v, Field2D &C_v, const char* name);
\end{lstlisting}
The \code{constraints()} function tests whether or not the current
solver supports constraints. The format of \code{constraint(...)} is
the same as \code{add}, except that now the solver will attempt to make
\code{C\_v} zero. If \code{constraint} is called when the solver doesn't
support them then an error should occur.

If the physics model implements a preconditioner or Jacobian-vector
multiplication routine, these can be passed to the solver during
initialisation:
\begin{lstlisting}
typedef int (*PhysicsPrecon)(BoutReal t, BoutReal gamma, BoutReal delta);
void setPrecon(PhysicsPrecon f); // Specify a preconditioner
typedef int (*Jacobian)(BoutReal t);
void setJacobian(Jacobian j); // Specify a Jacobian
\end{lstlisting}
If the solver doesn't support these functions then the calls 
will just be ignored.

Once the problem to be solved has been specified, the solver can be
initialised using:
\begin{lstlisting}
int init(rhsfunc f, int argc, char **argv, bool restarting, int nout, BoutReal tstep);
\end{lstlisting}
which returns an error code (0 on success). This is currently
called in \file{bout++.cxx}:
\begin{lstlisting}
if(solver.init(physics_run, argc, argv, restart, NOUT, TIMESTEP)) {
  output.write("Failed to initialise solver. Aborting\n");
  return(1);
}
\end{lstlisting}
which passes the (physics module) RHS function \code{physics\_run}
to the solver along with the number and size of the output steps.

To run the solver using the (already supplied) settings, there is
the function:
\begin{lstlisting}
typedef int (*MonitorFunc)(BoutReal simtime, int iter, int NOUT);
int run(MonitorFunc f);
\end{lstlisting}

\subsection{Implementation: PVODE}


\subsection{Implementation: IDA}

\subsection{Implementation: PETSc}

\section{File I/O}

BOUT++ needs to deal with binary format files to read the grid;
read and write restart restart files; and write dump files. 
The two parts of the code which need to read and write data are therefore
the grid routines (\code{grid.hxx} and \code{grid.cxx}), and the
\code{Datafile} class (\code{datafile.hxx} and \code{datafile.cxx}).
All other parts which need to read or write data go through these
methods.

Several different file formats are commonly used, such as HDF, HDF5, and netCDF.
For historical reasons (inherited from BOUT), BOUT++ originally used the
Portable Data Binary (PDB) format developed at LLNL.
%
\footnote{Support for PDB files was removed in BOUT++ 4.0.0}
%
To separate the basic file format functions from the higher level grid and
Datafile classes, these use an abstract class \code{DataFormat}. Any
class which implements the functions listed in \code{dataformat.hxx}
can therefore be passed to grid or datafile. This makes implementing
a new file format, and switching between formats at run-time,
relatively straightforward.


Access to data in files is provided using a Bridge pattern: The
\code{Datafile} class provides an interface to the rest of the code
to read and write variables, whilst file formats implement the
\code{Dataformat} interface. \index{Datafile}
\begin{lstlisting}
class Datafile {
 public:
  Datafile();
  Datafile(DataFormat *format);
  ~Datafile();
  
  /// Set the file format by passing an interface class
  void setFormat(DataFormat *format);

  void setLowPrecision(); ///< Only output floats

  void add(var, const char *name, int grow = 0);

  int read(const char *filename, ...);
  int write(const char *filename, ...);
  int append(const char *filename, ...);
  bool write(const string &filename, bool append=false);

  /// Set this to false to switch off all data writing
  static bool enabled;
};
\end{lstlisting}


The important bits of the DataFormat interface are: \index{DataFormat}
\begin{lstlisting}
class DataFormat {
 public:
  bool openr(const char *name);
  bool openw(const char *name, bool append=false);
  
  bool is_valid();
  
  void close();
  
  const char* filename();

  const vector<int> getSize(const char *var);
  const vector<int> getSize(const string &var);

  // Set the origin for all subsequent calls
  bool setOrigin(int x = 0, int y = 0, int z = 0); 
  bool setRecord(int t); // negative -> latest
  
  // Read / Write simple variables up to 3D

  bool read(int *var, const char *name, int lx = 1, int ly = 0, int lz = 0);
  bool read(BoutReal *var, const char *name, int lx = 1, int ly = 0, int lz = 0);

  bool write(int *var, const char *name, int lx = 0, int ly = 0, int lz = 0);
  bool write(BoutReal *var, const char *name, int lx = 0, int ly = 0, int lz = 0);

  // Read / Write record-based variables

  bool read_rec(int *var, const char *name, int lx = 1, int ly = 0, int lz = 0);
  bool read_rec(BoutReal *var, const char *name, int lx = 1, int ly = 0, int lz = 0);

  bool write_rec(int *var, const char *name, int lx = 0, int ly = 0, int lz = 0);
  bool write_rec(BoutReal *var, const char *name, int lx = 0, int ly = 0, int lz = 0);

  // Optional functions
  
  void setLowPrecision();
};
\end{lstlisting}


\section{Miscellaneous}

Other small modules which don't really fit into any system, but are needed.


\subsection{Printing messages}


\subsection{Iterating over ranges}
\label{sec:rangeiterator}
\index{RangeIterator}

The boundary of a processor's domain may consist of a set of disjoint ranges, so 
the mesh needs a clean way to tell any code which depends on the boundary how to iterate over it.
The \lstinline!RangeIterator! class in \file{include/bout/sys/range.hxx} and \file{src/sys/range.cxx}
provides this.

RangeIterator can represent a single continuous range, constructed by passing
the minimum and maximum values. 
\begin{lstlisting}
RangeIterator it(1,4);  // Range includes both end points
for(it.first(); !it.isDone(); it.next())
  cout << it.ind; // Prints 1234
\end{lstlisting}

A more canonical C++ style is also supported, using overloaded \lstinline!++!, \lstinline!*!, and \lstinline!!=!
operators:
\begin{lstlisting}
for(it.first(); it != RangeIterator::end(); it++)
  cout << *it; // Prints 1234
\end{lstlisting}
where \lstinline!it++! is the same as \lstinline!it.next()!, and \lstinline!*it! the same as \lstinline!it.ind!.

To iterate over several ranges, \lstinline!RangeIterator! can be constructed with the next range as an
argument:
\begin{lstlisting}
RangeIterator it(1,4, RangeIterator(6,9));
for(it.first(); it != RangeIterator::end(); it++)
  cout << *it; // Prints 12346789
\end{lstlisting}
and these can be chained together to an arbitrary depth.

To support statements like
\begin{lstlisting}
for(RangeIterator it = mesh->iterateBndryLowerY(); !it.isDone(); it++)
  ...
\end{lstlisting}
the initial call to \lstinline!first()! is optional, and everything is initialised in the constructor.


\subsection{Error handling}



\bibliography{references}
\bibliographystyle{unsrt}

\printindex

\end{document}

